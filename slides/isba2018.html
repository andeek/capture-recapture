<!DOCTYPE html>
<html>
  <head>
    <title>Population Sized Record Linkage</title>
    <meta charset="utf-8">
    <meta name="author" content="Andee Kaplan" />
    <link href="isba2018_files/remark-css-0.0.1/default.css" rel="stylesheet" />
    <link href="isba2018_files/remark-css-0.0.1/default-fonts.css" rel="stylesheet" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# Population Sized Record Linkage
## <a href="http://bit.ly/isba-2018" class="uri">http://bit.ly/isba-2018</a>
### Andee Kaplan
### ISBA 2018 <br/><br/><small>Joint work with Rebecca C. Steorts</small>

---



```
## 
## Attaching package: 'dplyr'
```

```
## The following objects are masked from 'package:stats':
## 
##     filter, lag
```

```
## The following objects are masked from 'package:base':
## 
##     intersect, setdiff, setequal, union
```

# Motivating example

.pull-left[
![](figure/nytimes_syria.png)&lt;!-- --&gt;
]

.pull-right[

- Duplicated information regarding information about who has died from multiple sources (NGOs)
- Messy overlapping datasets with errors
- String data (names) as identifiers
]

 &gt;  Historically, these numbers matter... because they can have a direct impact on policy, accountability and a global sense of urgency.
 
 **Goal:** We want to count the (population) of casualties and *quantify the uncertainty* in this estimate.

.footnote[[1] https://www.nytimes.com/2018/04/13/world/middleeast/syria-death-toll.html]

---
# General terminology

![](figure/overall_process.png)

* *Record linkage* is merging together multiple datasets that have duplicate entries (often in the absence of a unique identifier). 

* A *downstream task* is inference, prediction, or post-linkage analysis on the linked data. 
  - Examples: regression, clustering, small area estimation, sample size estimation, population size estimation, etc.

* *Capture-recapture (CRC)* is a method used to estimate a closed population's size through the use of mark-release-recapture.



---
# Proposed work

* Much work has focused on sample size estimation as the downstream task [TODO: cite, include HRDAG]
  - Limited work on population size estimation post-linkage with uncertainty quantification [TODO: cite]

* We look at a general fully Bayesian approach, in the context of the downstream task

* Provide framework for record linkage and CRC, where we crucially account for the record linkage and model uncertainty 

---
# Probabilistic record linkage

what is it

---
# Simple example

picture example showing latent clustering idea

---
# Bayesian hierarchical model

![](figure/recordLinkage_graphicalModel.svg)

---
# Capture-recapture

what is it

---
# Simple example

small example picture + contingency table

---
# Bayesian nonparametric latent class model

---
# Record linkage + CRC
 

 list  fname     lname        by     bm   bd 
-----  --------  -----------  -----  ---  ---
    1  edward    zimmermann   1994   07   19 
    1  edwa"d    zimm@rmann   1994   07   22 
    1  ~dward    zimmeDmann   1994   07   16 
    2  ed%ard    ziVmermann   1994   07   20 
    2  finnbar   armanious    1980   03   03 
    1  jack      campbell     1998   10   07 



---
# Propagating record linkage uncertainty

**Recall Goal: ** We want to count the (population) of casualties and *quantify the uncertainty* in this estimate.

**Challenge: ** How to quantify record linkage uncertainty after the record linkage task in finished and propagate this error into these subsequent analyses?

**One way: **

`$$U(\eta) =: E_{\boldsymbol \lambda \mid \boldsymbol X} [p_C(\eta \mid f(\boldsymbol \lambda))] = \sum_{\boldsymbol \lambda} p_C(\eta \mid f(\boldsymbol \lambda)) p(\boldsymbol \lambda \mid \boldsymbol X) = p(\eta \mid \boldsymbol X)$$`
`$$\text{Var} (\eta \mid \boldsymbol X) = \text{Var}_{\boldsymbol \lambda \mid \boldsymbol X} [E[\eta \mid \boldsymbol \lambda ]] + E_{\boldsymbol \lambda \mid \boldsymbol X} [\text{Var}[\eta \mid \boldsymbol \lambda ]]$$`

In practice, `\(U(\eta)\)` and `\(\text{Var} (\eta \mid \boldsymbol X)\)` must be estimated by Markov chain Monte carlo (MCMC).


---
# Another way

- Estimating `\(U(\eta)\)` and `\(\text{Var} (\eta \mid \boldsymbol X)\)` through MCMC can be computationally burdensome.

- Could also consider `\(p_C(\eta \mid f(\hat{\boldsymbol \lambda}))\)`, where `\(\hat{\boldsymbol \lambda}\)` is the posterior mean of `\(\boldsymbol \lambda | \boldsymbol X\)` (TODO: look up correct statement here) given my the shared most probable matching sets (TODO: cite mpmms)

- Downside: error doesn't propogate through CRC task

---
# Simulated examples



---
# Future work


- MCMC for estimation of `\(U(\eta)\)` and `\(\text{Var} (\eta \mid \boldsymbol X)\)` is **computationally expensive**. Explore how to propogate the error approximately.

- CRC method is for independent lists. How to extend for dependency between lists?

- In our (limited) experience, this CRC method works best for many recaptures ( `\(\ge 4\)` ), but record linkage works best for smaller numbers of lists ( `\(\le 3\)` ). How to navigate this tradeoff?

- Much more extensive simulation with different levels of duplication and list inclusion probabilities.

- Do this on **real data**!

&lt;img src="figure/do_this.gif" height="150px" /&gt;


---
# Thank you

## Questions?

### Slides - &lt;http://bit.ly/isba-2018&gt;

### Contact

* Email - &lt;andrea.kaplan@duke.edu&gt;
* Twitter - &lt;http://twitter.com/andeekaplan&gt;
* GitHub - &lt;http://github.com/andeek&gt;

---
# Notation

---
# Bayesian hierarchical model for record linkage

---
# Bayesian nonparametric latent class model

---
# References
    </textarea>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create();
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function() {
  var d = document, s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})();</script>

<script>
(function() {
  var i, text, code, codes = document.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
})();
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
