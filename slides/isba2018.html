<!DOCTYPE html>
<html>
  <head>
    <title>Population Sized Record Linkage</title>
    <meta charset="utf-8">
    <meta name="author" content="Andee Kaplan" />
    <link href="isba2018_files/remark-css-0.0.1/default.css" rel="stylesheet" />
    <link href="isba2018_files/remark-css-0.0.1/default-fonts.css" rel="stylesheet" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# Population Sized Record Linkage
## <a href="http://bit.ly/isba-2018" class="uri">http://bit.ly/isba-2018</a>
### Andee Kaplan
### ISBA 2018 <br/><br/><small>Joint work with Rebecca C. Steorts</small>

---




# Motivating example

.pull-left[
![](figure/nytimes_syria.png)&lt;!-- --&gt;
]

.pull-right[

- Duplicated information regarding information about who has died from multiple sources (NGOs)
- Messy overlapping datasets with errors
- String data (names) as identifiers
]

 &gt;  Historically, these numbers matter... because they can have a direct impact on policy, accountability and a global sense of urgency.
 
 **Goal:** We want to count the (population) of casualties and *quantify the uncertainty* in this estimate.

.footnote[[1] https://www.nytimes.com/2018/04/13/world/middleeast/syria-death-toll.html]

---
# General terminology

![](figure/overall_process.png)

* *Record linkage* is merging together multiple datasets that have duplicate entries (often in the absence of a unique identifier). 

* A *downstream task* is inference, prediction, or post-linkage analysis on the linked data. 
  - Examples: regression, clustering, small area estimation, sample size estimation, population size estimation, etc.

* *Capture-recapture (CRC)* is a method used to estimate a closed population's size through the use of mark-release-recapture.



---
# Proposed work

* Much work has focused on sample size estimation as the downstream task [TODO: cite, include HRDAG]
  - Limited work on population size estimation post-linkage with uncertainty quantification [TODO: cite]

* We look at a general fully Bayesian approach, in the context of the downstream task

* Provide framework for record linkage and CRC, where we crucially account for the record linkage and model uncertainty 

---
# Probabilistic record linkage

*Record linkage* is merging together multiple datasets that have duplicate entries (often in the absence of a unique identifier). 

what is it

---
# Simple example

picture example showing latent clustering idea

---
# Bayesian hierarchical model

![](figure/recordLinkage_graphicalModel.svg)

---
# Capture-recapture

*Capture-recapture (CRC)* is a method used to estimate a closed population's size through the use of mark-release-recapture.

![](figure/crc.png)

---
# Simple example

small example picture + contingency table

---
# Bayesian nonparametric latent class model

---
# Record linkage + CRC
 

 


![](figure/rl_crc.png)

---
# Propagating record linkage uncertainty

**Recall Goal: ** We want to count the (population) of casualties and *quantify the uncertainty* in this estimate.

**Challenge: ** How to quantify record linkage uncertainty after the record linkage task in finished and propagate this error into these subsequent analyses?

**One way: **

`$$U(\eta) =: E_{\boldsymbol \lambda \mid \boldsymbol X} [p_C(\eta \mid f(\boldsymbol \lambda))] = \sum_{\boldsymbol \lambda} p_C(\eta \mid f(\boldsymbol \lambda)) p(\boldsymbol \lambda \mid \boldsymbol X) = p(\eta \mid \boldsymbol X)$$`
`$$\text{Var} (\eta \mid \boldsymbol X) = \text{Var}_{\boldsymbol \lambda \mid \boldsymbol X} [E[\eta \mid \boldsymbol \lambda ]] + E_{\boldsymbol \lambda \mid \boldsymbol X} [\text{Var}[\eta \mid \boldsymbol \lambda ]]$$`

In practice, `\(U(\eta)\)` and `\(\text{Var} (\eta \mid \boldsymbol X)\)` must be estimated by Markov chain Monte carlo (MCMC).


---
# Another way

- Estimating `\(U(\eta)\)` and `\(\text{Var} (\eta \mid \boldsymbol X)\)` through MCMC can be computationally burdensome.

- Could also consider `\(p_C(\eta \mid f(\hat{\boldsymbol \lambda}))\)`, where `\(\hat{\boldsymbol \lambda}\)` is the posterior mean of `\(\boldsymbol \lambda | \boldsymbol X\)` (TODO: look up correct statement here) given my the shared most probable matching sets (TODO: cite mpmms)

- Downside: error doesn't propogate through CRC task in an obvious way

---
# Simulated examples

- Generated data in 5 lists according to the following stratified capture probabilities

&lt;table&gt;
 &lt;thead&gt;
  &lt;tr&gt;
   &lt;th style="text-align:right;"&gt; Strata &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; Proportion &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; List 1 &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; List 2 &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; List 3 &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; List 4 &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; List 5 &lt;/th&gt;
  &lt;/tr&gt;
 &lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr&gt;
   &lt;td style="text-align:right;"&gt; 1 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.75 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.07 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.31 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.17 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.31 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.14 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:right;"&gt; 2 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.25 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.94 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.77 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.85 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.90 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.91 &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

- Strata correspond to (1) a large &amp; hard to capture population and (2) a small &amp; easy to capture population.

- Add additional duplicates within each database at a 5% level

- Distort the duplicates (both between and within). String fields are distorted at three different levels: `\(5\%, 10\%, 15\%\)` of characters

---
# Simulated data

&lt;table&gt;
 &lt;thead&gt;
  &lt;tr&gt;
   &lt;th style="text-align:left;"&gt; fname &lt;/th&gt;
   &lt;th style="text-align:left;"&gt; lname &lt;/th&gt;
   &lt;th style="text-align:left;"&gt; by &lt;/th&gt;
   &lt;th style="text-align:left;"&gt; bm &lt;/th&gt;
   &lt;th style="text-align:left;"&gt; bd &lt;/th&gt;
  &lt;/tr&gt;
 &lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; jacobiT &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; aqns &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 1981 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 11 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 30 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; jacobLe &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; znns &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 1981 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 12 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 15 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; amaya &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; mcmellon &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 1985 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 08 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 17 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; daniel &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; jetter &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 1983 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 05 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 31 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; lachlan &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; ringland &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 1992 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 08 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 05 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; nicholas &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; cadman &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 1985 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 03 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 05 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; alessandria &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; wheatley &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 1995 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 05 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 07 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; tommy &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; eglinton &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 1991 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 09 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 07 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; tristan &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; ryan &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 1996 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 04 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 19 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; tristan &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; blake &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 1983 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 04 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 21 &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

---
# Results

---
# Future work &amp; Challenges


- MCMC for estimation of `\(U(\eta)\)` and `\(\text{Var} (\eta \mid \boldsymbol X)\)` is **computationally expensive**. Explore how to propogate the error approximately.

- CRC method is for independent lists. How to extend for dependency between lists?

- In our (limited) experience, this CRC method works best for many recaptures ( `\(\ge 4\)` ), but record linkage works best for smaller numbers of lists ( `\(\le 3\)` ). How to navigate this tradeoff?

- Much more extensive simulation with different levels of duplication and list inclusion probabilities.

- Do this on **real data**!

&lt;img src="figure/do_this.gif" height="150px" /&gt;


---
# Thank you

## Questions?

### Slides - &lt;http://bit.ly/isba-2018&gt;

### Contact

* Email - &lt;andrea.kaplan@duke.edu&gt;
* Twitter - &lt;http://twitter.com/andeekaplan&gt;
* GitHub - &lt;http://github.com/andeek&gt;

---
# Notation

`\(\boldsymbol X=(X_1,\ldots,X_n)\)`, records comprised of `\(D\)` databases, indexed by `\(i\)`   

`\(i\)`th database has `\(n_i\)` observed records, indexed by `\(j\)`  

Each record corresponds to one of `\(M\)` latent entities, indexed by `\(j'\)`  

Each record or latent entity has values on `\(p\)` fields, indexed by `\(\ell\)`, assumed to be categorical or string  

`\(M_\ell\)`, the number of possible categorical values for the `\(\ell\)`th field  

`\(X_{ij\ell}\)`, observed value of the `\(\ell\)`th field for the `\(j\)`th record in the `\(i\)`th database  

`\(Y_{j'\ell}\)`, true value of the `\(\ell\)`th field for the `\(j'\)`th latent entity  

`\(\Lambda_{ij}\)`, latent entity to which the `\(j\)`th record in the `\(i\)`th database corresponds  

`\(\boldsymbol \Lambda = \{\Lambda_{ij}: i = 1, \dots, D, j = 1, \dots, n_i\}\)`   

`\(z_{ij\ell}=I(X_{ij\ell}\ne Y_{\Lambda_{ij}\ell})\)`, distortion indicator  

---
# Bayesian hierarchical model for RL

`$$X_{ij\ell} \mid \Lambda_{ij},\,Y_{\Lambda_{ij}\ell},\,z_{ij\ell} \stackrel{\text{ind}}{\sim}\begin{cases}\delta(Y_{\Lambda_{ij}\ell})&amp;\text{ if }z_{ij\ell}=0\\F_\ell(Y_{\Lambda_{ij}\ell})&amp;\text{ if }z_{ij\ell}=1, \ell\le p_s\\G_\ell&amp;\text{ if }z_{ij\ell}=1, \ell&gt;p_s\end{cases}$$`
`$$Y_{j'\ell}\stackrel{\text{ind}}{\sim}G_\ell$$`
`$$z_{ij\ell}\mid\beta_{i\ell}\stackrel{\text{ind}}{\sim}\text{Bernoulli}(\beta_{i\ell})$$`
`$$\beta_{i\ell} \mid a,b \stackrel{\text{ind}}{\sim}\text{Beta}(a,b)$$`
`$$\Lambda_{ij} \mid M\stackrel{\text{ind}}{\sim}\text{Uniform}\left(1,\ldots, M\right)$$`



---
# Bayesian nonparametric latent class model

`$$f(\boldsymbol q | \boldsymbol \gamma, \boldsymbol \pi) = \sum\limits_{k = 1}^{K^*} \pi_k \prod\limits_{j = 1}^D \gamma_{jk}^{q_j}(1-\gamma{jk})^{1-q_j},$$`
`$$(\pi_1, \dots, \pi_{K^*}) \sim \text{SB}_{K^*}(\alpha)$$`
`$$\gamma_{jk} \stackrel{iid}{\sim} \text{Beta}(a_\gamma, b_\gamma)$$`
`$$\alpha \sim \text{Gamma}(a_\alpha, b_\alpha)$$`
`$$p(N) \propto \frac{1}{N}$$`

---
# Trace plots

---
# Precision and recall

---
# References
    </textarea>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create();
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function() {
  var d = document, s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})();</script>

<script>
(function() {
  var i, text, code, codes = document.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
})();
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
